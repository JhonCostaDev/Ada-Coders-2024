{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffbe4821-9768-4915-9ae5-31ef9329fb59",
     "showTitle": false,
     "title": ""
    },
    "id": "SPK6GHpzzoyj"
   },
   "source": [
    "# Extract, Transform, Load (ETL)\n",
    "\n",
    "No mundo do gerenciamento de dados, o processo **Extrair, Transformar, Carregar (ETL)** é uma etapa fundamental na coleta, processamento e preparação de dados para análise. ETL envolve extrair dados de diversas fontes, transformá-los em um formato estruturado e carregá-los em um destino onde possam ser analisados. Este processo é crucial para manter a qualidade e a consistência dos dados.\n",
    "\n",
    "## 1. Extração (E)\n",
    "\n",
    "\n",
    "\n",
    "A primeira etapa do ETL é a **extração**, onde os dados são coletados de diferentes fontes. Essas fontes podem incluir bancos de dados, planilhas, APIs, logs e muito mais. Aqui estão alguns exemplos:\n",
    "\n",
    "- Extraindo dados de um banco de dados:\n",
    "\n",
    "```sql\n",
    "SELECT * FROM sales_data;\n",
    "```\n",
    "\n",
    "- Extraindo dados de uma API REST:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "response = requests.get(\"https://api.example.com/data\")\n",
    "data = response.json()\n",
    "```\n",
    "\n",
    "## 2. Transformação (T)\n",
    "\n",
    "\n",
    "\n",
    "Após a extração dos dados, a próxima etapa é a **transformação**. Durante esta fase, os dados são limpos, enriquecidos e transformados em um formato consistente. A transformação pode envolver:\n",
    "\n",
    "- Removendo duplicatas\n",
    "- Tratamento de valores ausentes\n",
    "- Agregando dados\n",
    "- Alteração de tipos de dados\n",
    "- Normalizando dados\n",
    "\n",
    "Por exemplo, transformando um formato de data de `MM/DD/AAAA` para `AAAA-MM-DD`:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'], format='%m/%d/%Y').dt.strftime('%Y-%m-%d')\n",
    "```\n",
    "\n",
    "## 3. Carga (L)\n",
    "\n",
    "\n",
    "\n",
    "A etapa final do ETL é **carregar** os dados transformados em um destino, normalmente um data warehouse, banco de dados ou data lake. Aqui estão alguns exemplos de carregamento:\n",
    "\n",
    "- Carregando dados em um banco de dados SQL:\n",
    "\n",
    "```sql\n",
    "INSERT INTO target_table\n",
    "SELECT * FROM transformed_data;\n",
    "```\n",
    "\n",
    "- Carregar dados em um data warehouse na nuvem como o Amazon Redshift:\n",
    "\n",
    "```python\n",
    "import psycopg2\n",
    "\n",
    "# Conectando ao redshift\n",
    "conn = psycopg2.connect(database=\"mydb\", user=\"user\", password=\"password\", host=\"redshift-cluster-url\")\n",
    "\n",
    "# Inserindo dados na tabela\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"COPY target_table FROM 's3://data-bucket/transformed_data.csv' CSV;\")\n",
    "conn.commit()\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82aef82c-70a5-4b29-a8f2-a8f8a2cab3a5",
     "showTitle": false,
     "title": ""
    },
    "id": "y746lvea1D3x"
   },
   "source": [
    "# ETL vs. ELT: Extrair, Transformar, Carregar vs. Extrair, Carregar, Transformar\n",
    "\n",
    "No campo da integração de dados, existem duas abordagens principais: **ETL** (Extrair, Transformar, Carregar) e **ELT** (Extrair, Carregar, Transformar). Estas metodologias diferem em suas sequências de processamento de dados e apresentam diferentes vantagens e casos de uso.\n",
    "\n",
    "## Comparação entre ETL e ELT\n",
    "\n",
    "- **Ordem das Etapas**:\n",
    "  - **ETL**: Extrair → Transformar → Carregar\n",
    "  - **ELT**: Extrair → Carregar → Transformar\n",
    "\n",
    "## Quando usar ETL:\n",
    "\n",
    "Quando precisamos garantir que os dados estão limpos e transformados antes de carregá-los no destino.\n",
    "Útil se o destino não tem capacidade de processamento suficiente para grandes transformações.\n",
    "## Quando usar ELT:\n",
    "\n",
    "Quando queremos carregar os dados rapidamente e realizar as transformações no próprio destino.\n",
    "Útil para grandes volumes de dados, aproveitando o poder de processamento do sistema de destino.\n",
    "\n",
    "## Principais Diferenças\n",
    "\n",
    "**ETL (Extrair, Transformar, Carregar):**\n",
    "- **Transformação Antes do Carregamento:** Os dados são limpos e transformados antes do carregamento no sistema de destino.\n",
    "- **Dados Estruturados:** Mais adequado para dados estruturados.\n",
    "- **Data Warehousing:** Frequentemente usado em sistemas de DW.\n",
    "- **Consistência:** A transformação ocorre antes do armazenamento, garantindo consistência.\n",
    "\n",
    "**ELT (Extrair, Carregar, Transformar):**\n",
    "- **Transformação Após o Carregamento:** Os dados são carregados no sistema de destino em seu estado bruto e transformados posteriormente.\n",
    "- **Dados Brutos e Não Estruturados:** Ideal para dados brutos e não estruturados.\n",
    "- **Data Lakes:** Comum em arquiteturas de data lake.\n",
    "- **Flexibilidade:** A transformação ocorre após o armazenamento, permitindo maior flexibilidade na análise.\n",
    "\n",
    "## Exemplo de ETL (Extrair, Transformar, Carregar)\n",
    "\n",
    "### Cenário:\n",
    "Temos um arquivo CSV com dados de vendas que precisa ser limpo e transformado antes de ser salvo em outro arquivo CSV.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Extração\n",
    "data = pd.read_csv('sales_data.csv')\n",
    "\n",
    "# Transformação\n",
    "data['date'] = pd.to_datetime(data['date'], format='%Y-%m-%d')\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Carregamento\n",
    "data.to_csv('cleaned_sales_data.csv', index=False)\n",
    "```\n",
    "\n",
    "## Exemplo de ELT (Extrair, Carregar, Transformar)\n",
    "\n",
    "### Cenário:\n",
    "Temos um arquivo CSV com dados de log de eventos que precisa ser carregado em um arquivo CSV bruto e depois transformado para análise.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Extração e Carga\n",
    "data = pd.read_csv('event_logs.csv')\n",
    "data.to_csv('raw_event_logs.csv', index=False)\n",
    "\n",
    "# Transformação\n",
    "transformed_data = data.groupby('user_id').agg(\n",
    "    event_count=('event_type', 'count'),\n",
    "    first_event=('event_timestamp', 'min'),\n",
    "    last_event=('event_timestamp', 'max')\n",
    ").reset_index()\n",
    "\n",
    "# Salvando os dados transformados\n",
    "transformed_data.to_csv('transformed_event_logs.csv', index=False)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1078951473893485,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "AULA_1_DE",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
